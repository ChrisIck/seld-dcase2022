{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "import cls_data_generator\n",
    "import cls_feature_class\n",
    "import parameters\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SET: 1\n",
      "USING DEFAULT PARAMETERS\n",
      "\n",
      "Loading data from /scratch/ci411/SELD_Datasets/TFR_0527\n",
      "\tquick_test: False\n",
      "\tfinetune_mode: False\n",
      "\tpretrained_model_weights: None\n",
      "\tdataset_dir: /scratch/ci411/SELD_Datasets/TFR_0527\n",
      "\tfeat_label_dir: /scratch/ci411/DCASE_GEN/seld_features/TFR_0527\n",
      "\tmodel_dir: models/\n",
      "\tdcase_output_dir: results/\n",
      "\tmode: dev\n",
      "\tdataset: mic\n",
      "\tunique_classes: 14\n",
      "\tfs: 24000\n",
      "\thop_len_s: 0.02\n",
      "\tlabel_hop_len_s: 0.1\n",
      "\tmax_audio_len_s: 60\n",
      "\tnb_mel_bins: 64\n",
      "\tuse_salsalite: False\n",
      "\tfmin_doa_salsalite: 50\n",
      "\tfmax_doa_salsalite: 2000\n",
      "\tfmax_spectra_salsalite: 9000\n",
      "\tmulti_accdoa: False\n",
      "\tthresh_unify: 15\n",
      "\tlabel_sequence_length: 50\n",
      "\tbatch_size: 256\n",
      "\tdropout_rate: 0.05\n",
      "\tnb_cnn2d_filt: 64\n",
      "\tf_pool_size: [4, 4, 2]\n",
      "\tnb_rnn_layers: 2\n",
      "\trnn_size: 128\n",
      "\tself_attn: False\n",
      "\tnb_heads: 4\n",
      "\tnb_fnn_layers: 1\n",
      "\tfnn_size: 128\n",
      "\tnb_epochs: 100\n",
      "\tlr: 0.001\n",
      "\taverage: macro\n",
      "\tlad_doa_thresh: 20\n",
      "\tfeature_sequence_length: 250\n",
      "\tt_pool_size: [5, 1, 1]\n",
      "\tpatience: 100\n"
     ]
    }
   ],
   "source": [
    "task_id = '1'\n",
    "params = parameters.get_params(task_id)\n",
    "train_splits = [[1, 2, 3]] \n",
    "split_cnt = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(object):\n",
    "    def __init__(\n",
    "            self, params, split=1, shuffle=True, per_file=False, is_eval=False\n",
    "    ):\n",
    "        self._per_file = per_file\n",
    "        self._is_eval = is_eval\n",
    "        self._splits = np.array(split)\n",
    "        self._batch_size = params['batch_size']\n",
    "        self._feature_seq_len = params['feature_sequence_length']\n",
    "        self._label_seq_len = params['label_sequence_length']\n",
    "        self._shuffle = shuffle\n",
    "        self._feat_cls = cls_feature_class.FeatureClass(params=params, is_eval=self._is_eval)\n",
    "        self._label_dir = self._feat_cls.get_label_dir()\n",
    "        self._feat_dir = self._feat_cls.get_normalized_feat_dir()\n",
    "        self._multi_accdoa = params['multi_accdoa']\n",
    "\n",
    "        self._filenames_list = list()\n",
    "        self._nb_frames_file = 0     # Using a fixed number of frames in feat files. Updated in _get_label_filenames_sizes()\n",
    "        self._nb_mel_bins = self._feat_cls.get_nb_mel_bins()\n",
    "        self._nb_ch = None\n",
    "        self._label_len = None  # total length of label - DOA + SED\n",
    "        self._doa_len = None    # DOA label length\n",
    "        self._nb_classes = self._feat_cls.get_nb_classes()\n",
    "\n",
    "        self._circ_buf_feat = None\n",
    "        self._circ_buf_label = None\n",
    "\n",
    "        self._get_filenames_list_and_feat_label_sizes()\n",
    "\n",
    "        print(\n",
    "            '\\tDatagen_mode: {}, nb_files: {}, nb_classes:{}\\n'\n",
    "            '\\tnb_frames_file: {}, feat_len: {}, nb_ch: {}, label_len:{}\\n'.format(\n",
    "                'eval' if self._is_eval else 'dev', len(self._filenames_list),  self._nb_classes,\n",
    "                self._nb_frames_file, self._nb_mel_bins, self._nb_ch, self._label_len\n",
    "                )\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            '\\tDataset: {}, split: {}\\n'\n",
    "            '\\tbatch_size: {}, feat_seq_len: {}, label_seq_len: {}, shuffle: {}\\n'\n",
    "            '\\tTotal batches in dataset: {}\\n'\n",
    "            '\\tlabel_dir: {}\\n '\n",
    "            '\\tfeat_dir: {}\\n'.format(\n",
    "                params['dataset'], split,\n",
    "                self._batch_size, self._feature_seq_len, self._label_seq_len, self._shuffle,\n",
    "                self._nb_total_batches,\n",
    "                self._label_dir, self._feat_dir\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def get_data_sizes(self):\n",
    "        feat_shape = (self._batch_size, self._nb_ch, self._feature_seq_len, self._nb_mel_bins)\n",
    "        if self._is_eval:\n",
    "            label_shape = None\n",
    "        else:\n",
    "            if self._multi_accdoa is True:\n",
    "                label_shape = (self._batch_size, self._label_seq_len, self._nb_classes*3*3)\n",
    "            else:\n",
    "                label_shape = (self._batch_size, self._label_seq_len, self._nb_classes*3)\n",
    "        return feat_shape, label_shape\n",
    "\n",
    "    def get_total_batches_in_data(self):\n",
    "        return self._nb_total_batches\n",
    "\n",
    "    def _get_filenames_list_and_feat_label_sizes(self):\n",
    "        print(f'Computing some stats about the dataset in {self._feat_dir}')\n",
    "        max_frames, total_frames, temp_feat = -1, 0, []\n",
    "        for filename in os.listdir(self._feat_dir):\n",
    "            if int(filename[4]) in self._splits: # check which split the file belongs to\n",
    "                self._filenames_list.append(filename)\n",
    "                    \n",
    "                temp_feat = np.load(os.path.join(self._feat_dir, filename))\n",
    "                total_frames += (temp_feat.shape[0] - (temp_feat.shape[0] % self._feature_seq_len))\n",
    "                if temp_feat.shape[0]>max_frames:\n",
    "                    max_frames = temp_feat.shape[0]\n",
    "  \n",
    "        if len(temp_feat)!=0:\n",
    "            self._nb_frames_file = max_frames if self._per_file else temp_feat.shape[0]\n",
    "            self._nb_ch = temp_feat.shape[1] // self._nb_mel_bins\n",
    "        else:\n",
    "            print('Loading features failed')\n",
    "            exit()\n",
    "\n",
    "        if not self._is_eval:\n",
    "            temp_label = np.load(os.path.join(self._label_dir, self._filenames_list[0]))\n",
    "            if self._multi_accdoa is True:\n",
    "                self._num_track_dummy = temp_label.shape[-3]\n",
    "                self._num_axis = temp_label.shape[-2]\n",
    "                self._num_class = temp_label.shape[-1]\n",
    "            else:\n",
    "                self._label_len = temp_label.shape[-1]\n",
    "            self._doa_len = 3 # Cartesian\n",
    "\n",
    "        if self._per_file:\n",
    "            self._batch_size = int(np.ceil(max_frames/float(self._feature_seq_len)))\n",
    "            print('\\tWARNING: Resetting batch size to {}. To accommodate the inference of longest file of {} frames in a single batch'.format(self._batch_size, max_frames))\n",
    "            self._nb_total_batches = len(self._filenames_list)\n",
    "        else:\n",
    "            self._nb_total_batches = int(np.floor(total_frames / (self._batch_size*self._feature_seq_len)))\n",
    "\n",
    "        self._feature_batch_seq_len = self._batch_size*self._feature_seq_len\n",
    "        self._label_batch_seq_len = self._batch_size*self._label_seq_len\n",
    "        return\n",
    "\n",
    "    def generate(self):\n",
    "        \"\"\"\n",
    "        Generates batches of samples\n",
    "        :return: \n",
    "        \"\"\"\n",
    "        if self._shuffle:\n",
    "            random.shuffle(self._filenames_list)\n",
    "\n",
    "        # Ideally this should have been outside the while loop. But while generating the test data we want the data\n",
    "        # to be the same exactly for all epoch's hence we keep it here.\n",
    "        self._circ_buf_feat = deque()\n",
    "        self._circ_buf_label = deque()\n",
    "\n",
    "        file_cnt = 0\n",
    "        if self._is_eval:\n",
    "            for i in range(self._nb_total_batches):\n",
    "                # load feat and label to circular buffer. Always maintain atleast one batch worth feat and label in the\n",
    "                # circular buffer. If not keep refilling it.\n",
    "                while len(self._circ_buf_feat) < self._feature_batch_seq_len:\n",
    "                    temp_feat = np.load(os.path.join(self._feat_dir, self._filenames_list[file_cnt]))\n",
    "\n",
    "                    for row_cnt, row in enumerate(temp_feat):\n",
    "                        self._circ_buf_feat.append(row)\n",
    "\n",
    "                    # If self._per_file is True, this returns the sequences belonging to a single audio recording\n",
    "                    if self._per_file:\n",
    "                        extra_frames = self._feature_batch_seq_len - temp_feat.shape[0]\n",
    "                        extra_feat = np.ones((extra_frames, temp_feat.shape[1])) * 1e-6\n",
    "\n",
    "                        for row_cnt, row in enumerate(extra_feat):\n",
    "                            self._circ_buf_feat.append(row)\n",
    "\n",
    "                    file_cnt = file_cnt + 1\n",
    "\n",
    "                # Read one batch size from the circular buffer\n",
    "                feat = np.zeros((self._feature_batch_seq_len, self._nb_mel_bins * self._nb_ch))\n",
    "                for j in range(self._feature_batch_seq_len):\n",
    "                    feat[j, :] = self._circ_buf_feat.popleft()\n",
    "                feat = np.reshape(feat, (self._feature_batch_seq_len, self._nb_ch, self._nb_mel_bins))\n",
    "\n",
    "                # Split to sequences\n",
    "                feat = self._split_in_seqs(feat, self._feature_seq_len)\n",
    "                feat = np.transpose(feat, (0, 2, 1, 3))\n",
    "\n",
    "                yield feat\n",
    "\n",
    "        else:\n",
    "            for i in range(self._nb_total_batches):\n",
    "\n",
    "                # load feat and label to circular buffer. Always maintain atleast one batch worth feat and label in the\n",
    "                # circular buffer. If not keep refilling it.\n",
    "                while len(self._circ_buf_feat) < self._feature_batch_seq_len:\n",
    "                    temp_feat = np.load(os.path.join(self._feat_dir, self._filenames_list[file_cnt]))\n",
    "                    temp_label = np.load(os.path.join(self._label_dir, self._filenames_list[file_cnt]))\n",
    "                    if not self._per_file: \n",
    "                        # Inorder to support variable length features, and labels of different resolution. \n",
    "                        # We remove all frames in features and labels matrix that are outside \n",
    "                        # the multiple of self._label_seq_len and self._feature_seq_len. Further we do this only in training.\n",
    "                        temp_label = temp_label[:temp_label.shape[0] - (temp_label.shape[0] % self._label_seq_len)]\n",
    "                        temp_mul = temp_label.shape[0]//self._label_seq_len\n",
    "                        temp_feat = temp_feat[:temp_mul*self._feature_seq_len, :]\n",
    "\n",
    "                    for f_row in temp_feat:\n",
    "                        self._circ_buf_feat.append(f_row)\n",
    "                    for l_row in temp_label:\n",
    "                        self._circ_buf_label.append(l_row)\n",
    "                    \n",
    "                    # If self._per_file is True, this returns the sequences belonging to a single audio recording\n",
    "                    if self._per_file:\n",
    "                        feat_extra_frames = self._feature_batch_seq_len - temp_feat.shape[0]\n",
    "                        extra_feat = np.ones((feat_extra_frames, temp_feat.shape[1])) * 1e-6\n",
    "\n",
    "                        label_extra_frames = self._label_batch_seq_len - temp_label.shape[0]\n",
    "                        if self._multi_accdoa is True:\n",
    "                            extra_labels = np.zeros((label_extra_frames, self._num_track_dummy, self._num_axis, self._num_class))\n",
    "                        else:\n",
    "                            extra_labels = np.zeros((label_extra_frames, temp_label.shape[1]))\n",
    "\n",
    "                        for f_row in extra_feat:\n",
    "                            self._circ_buf_feat.append(f_row)\n",
    "                        for l_row in extra_labels:\n",
    "                            self._circ_buf_label.append(l_row)\n",
    "\n",
    "                    file_cnt = file_cnt + 1\n",
    "\n",
    "                # Read one batch size from the circular buffer\n",
    "                feat = np.zeros((self._feature_batch_seq_len, self._nb_mel_bins * self._nb_ch))\n",
    "                for j in range(self._feature_batch_seq_len):\n",
    "                    feat[j, :] = self._circ_buf_feat.popleft()\n",
    "                feat = np.reshape(feat, (self._feature_batch_seq_len, self._nb_ch, self._nb_mel_bins))\n",
    "\n",
    "                if self._multi_accdoa is True:\n",
    "                    label = np.zeros((self._label_batch_seq_len, self._num_track_dummy, self._num_axis, self._num_class))\n",
    "                    for j in range(self._label_batch_seq_len):\n",
    "                        label[j, :, :, :] = self._circ_buf_label.popleft()\n",
    "                else:\n",
    "                    label = np.zeros((self._label_batch_seq_len, self._label_len))\n",
    "                    for j in range(self._label_batch_seq_len):\n",
    "                        label[j, :] = self._circ_buf_label.popleft()\n",
    "                # Split to sequences\n",
    "                feat = self._split_in_seqs(feat, self._feature_seq_len)\n",
    "                feat = np.transpose(feat, (0, 2, 1, 3))\n",
    "                \n",
    "                label = self._split_in_seqs(label, self._label_seq_len)\n",
    "                if self._multi_accdoa is True:\n",
    "                    pass\n",
    "                else:\n",
    "                    mask = label[:, :, :self._nb_classes]\n",
    "                    mask = np.tile(mask, 3)\n",
    "                    label = mask * label[:, :, self._nb_classes:]\n",
    "\n",
    "                yield feat, label\n",
    "\n",
    "    def _split_in_seqs(self, data, _seq_len):\n",
    "        if len(data.shape) == 1:\n",
    "            if data.shape[0] % _seq_len:\n",
    "                data = data[:-(data.shape[0] % _seq_len), :]\n",
    "            data = data.reshape((data.shape[0] // _seq_len, _seq_len, 1))\n",
    "        elif len(data.shape) == 2:\n",
    "            if data.shape[0] % _seq_len:\n",
    "                data = data[:-(data.shape[0] % _seq_len), :]\n",
    "            data = data.reshape((data.shape[0] // _seq_len, _seq_len, data.shape[1]))\n",
    "        elif len(data.shape) == 3:\n",
    "            if data.shape[0] % _seq_len:\n",
    "                data = data[:-(data.shape[0] % _seq_len), :, :]\n",
    "            data = data.reshape((data.shape[0] // _seq_len, _seq_len, data.shape[1], data.shape[2]))\n",
    "        elif len(data.shape) == 4:  # for multi-ACCDOA with ADPIT\n",
    "            if data.shape[0] % _seq_len:\n",
    "                data = data[:-(data.shape[0] % _seq_len), :, :, :]\n",
    "            data = data.reshape((data.shape[0] // _seq_len, _seq_len, data.shape[1], data.shape[2], data.shape[3]))\n",
    "        else:\n",
    "            print('ERROR: Unknown data dimensions: {}'.format(data.shape))\n",
    "            exit()\n",
    "        return data\n",
    "\n",
    "    @staticmethod\n",
    "    def split_multi_channels(data, num_channels):\n",
    "        tmp = None\n",
    "        in_shape = data.shape\n",
    "        if len(in_shape) == 3:\n",
    "            hop = in_shape[2] / num_channels\n",
    "            tmp = np.zeros((in_shape[0], num_channels, in_shape[1], hop))\n",
    "            for i in range(num_channels):\n",
    "                tmp[:, i, :, :] = data[:, :, i * hop:(i + 1) * hop]\n",
    "        elif len(in_shape) == 4 and num_channels == 1:\n",
    "            tmp = np.zeros((in_shape[0], 1, in_shape[1], in_shape[2], in_shape[3]))\n",
    "            tmp[:, 0, :, :, :] = data\n",
    "        else:\n",
    "            print('ERROR: The input should be a 3D matrix but it seems to have dimensions: {}'.format(in_shape))\n",
    "            exit()\n",
    "        return tmp\n",
    "\n",
    "    def get_nb_classes(self):\n",
    "        return self._nb_classes\n",
    "\n",
    "    def nb_frames_1s(self):\n",
    "        return self._feat_cls.nb_frames_1s()\n",
    "\n",
    "    def get_hop_len_sec(self):\n",
    "        return self._feat_cls.get_hop_len_sec()\n",
    "\n",
    "    def get_filelist(self):\n",
    "        return self._filenames_list\n",
    "\n",
    "    def get_frame_per_file(self):\n",
    "        return self._label_batch_seq_len\n",
    "\n",
    "    def get_nb_frames(self):\n",
    "        return self._feat_cls.get_nb_frames()\n",
    "    \n",
    "    def get_data_gen_mode(self):\n",
    "        return self._is_eval\n",
    "\n",
    "    def write_output_format_file(self, _out_file, _out_dict):\n",
    "        return self._feat_cls.write_output_format_file(_out_file, _out_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing some stats about the dataset in /scratch/ci411/DCASE_GEN/seld_features/TFR_0527/mic_dev_norm\n",
      "\tDatagen_mode: dev, nb_files: 1267, nb_classes:14\n",
      "\tnb_frames_file: 3000, feat_len: 64, nb_ch: 10, label_len:56\n",
      "\n",
      "\tDataset: mic, split: [1, 2, 3]\n",
      "\tbatch_size: 256, feat_seq_len: 250, label_seq_len: 50, shuffle: True\n",
      "\tTotal batches in dataset: 64\n",
      "\tlabel_dir: /scratch/ci411/DCASE_GEN/seld_features/TFR_0527/mic_dev_label\n",
      " \tfeat_dir: /scratch/ci411/DCASE_GEN/seld_features/TFR_0527/mic_dev_norm\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_gen_train = DataGenerator(\n",
    "            params=params, split=train_splits[split_cnt]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "S3D Env",
   "language": "python",
   "name": "s3d_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
